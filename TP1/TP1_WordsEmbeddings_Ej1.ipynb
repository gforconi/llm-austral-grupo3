{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11d75532",
   "metadata": {},
   "source": [
    "# Ejercicio 1: \"Embeddings en español\" (obligatorio)\n",
    "\n",
    "Para palabras en español utilizaremos embeddings entrenados con FastText que hemos descargado del [repositorio](https://github.com/dccuchile/spanish-word-embeddings). Particularmente el archivo utilizado se puede descargar de [aquí](https://zenodo.org/record/3234051/files/embeddings-l-model.vec).\n",
    "\n",
    "El ejercicio consiste en:\n",
    "1. Cargar los embeddings linkeados utilizados la librería Gensim\n",
    "2. Dar 1 ejemplo de most_similar para una palabra en español.\n",
    "3. Dar 1 ejemplo de un \"fallo\" similar a lo que ocurría con \"trump\" en most_similar para una palabra en español: donde el embedding desconozca cierta información por el año en dodne fue entrenado.\n",
    "4. Dar 5 ejemplos de analogías. Es necesario reescribir la función analogy?\n",
    "5. Dar 1 ejemplo donde el modelo replique sesgos presentes en los datos que considere pernicioso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062097c1",
   "metadata": {},
   "source": [
    "# Solucion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d563e0d1",
   "metadata": {},
   "source": [
    "## 1\n",
    "\n",
    "Cargar los embeddings linkeados utilizados la librería Gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c871591-31e3-4130-b9ed-bda43d45464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a24c84-aefd-4453-b039-88ce0e26607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_es = KeyedVectors.load_word2vec_format('../models/embeddings-l-model.vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908f5fa6",
   "metadata": {},
   "source": [
    "## 2\n",
    "\n",
    "Dar 1 ejemplo de most_similar para una palabra en español.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db2311f7-4695-4762-b1b6-fced140a0de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('técnologica', 0.8358864784240723),\n",
       " ('tecnologico', 0.831659734249115),\n",
       " ('tecnologic', 0.8260371685028076),\n",
       " ('tecnologia', 0.8141574859619141),\n",
       " ('tecnologicas', 0.8090270757675171),\n",
       " ('innologica', 0.8072630763053894),\n",
       " ('tecnologi', 0.7988582253456116),\n",
       " ('biotecnologica', 0.7880196571350098),\n",
       " ('tecnologicos', 0.7810347676277161),\n",
       " ('tecnologicamente', 0.7714805603027344)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_es.most_similar('tecnologica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e77d7fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('patagónica', 0.70356684923172),\n",
       " ('australes', 0.7011647820472717),\n",
       " ('patagónico', 0.675995409488678),\n",
       " ('patagonia', 0.669646143913269),\n",
       " ('patagónicas', 0.6670447587966919),\n",
       " ('norpatagónico', 0.6669939756393433),\n",
       " ('norpatagónica', 0.6644687056541443),\n",
       " ('transpatagónico', 0.6595705151557922),\n",
       " ('andinopatagónica', 0.6575503945350647),\n",
       " ('australem', 0.6521563529968262)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_es.most_similar('austral')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431f57d0",
   "metadata": {},
   "source": [
    "## 3\n",
    "\n",
    "Dar 1 ejemplo de un \"fallo\" similar a lo que ocurría con \"trump\" en most_similar para una palabra en español: donde el embedding desconozca cierta información por el año en donde fue entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "633e76c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mileidy', 0.6162314414978027),\n",
       " ('archilei', 0.5704389810562134),\n",
       " ('milessi', 0.564062237739563),\n",
       " ('milea', 0.5424215793609619),\n",
       " ('zilei', 0.5419692397117615),\n",
       " ('leilei', 0.5339961051940918),\n",
       " ('montironi', 0.5273367762565613),\n",
       " ('jucilei', 0.5159412026405334),\n",
       " ('iannaccone', 0.5134119987487793),\n",
       " ('miledi', 0.5129122734069824)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_es.most_similar('milei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e00b31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('schabas', 0.7034784555435181),\n",
       " ('shabas', 0.6858364343643188),\n",
       " ('chabasse', 0.6649603247642517),\n",
       " ('gabas', 0.6557002067565918),\n",
       " ('marchabas', 0.6455830335617065),\n",
       " ('echabas', 0.6392748355865479),\n",
       " ('luchabas', 0.6377996802330017),\n",
       " ('duchabas', 0.6292291879653931),\n",
       " ('chaba', 0.6198267340660095),\n",
       " ('chabasita', 0.6149992942810059)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_es.most_similar('chabas') # pueblo de Santa Fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "953eb4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('arlucea', 0.8736236095428467),\n",
       " ('iberlucea', 0.7601783275604248),\n",
       " ('marluce', 0.6363034844398499),\n",
       " ('brandsen', 0.6354255676269531),\n",
       " ('aberastegui', 0.626965343952179),\n",
       " ('quinteros', 0.6264732480049133),\n",
       " ('anzorena', 0.623516857624054),\n",
       " ('echeverria', 0.621390163898468),\n",
       " ('amuátegui', 0.614928126335144),\n",
       " ('etcheverri', 0.6147255897521973)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_es.most_similar('ibarlucea') # pueblo de Santa Fe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995affb3",
   "metadata": {},
   "source": [
    "En los dos ultimos ejemplos pusimos nombres de localidades de la privincia de Santa Fe, con Chabas tuvimos un \"fallo\" y en Ibarlucea misma situacion, sancando una de las ultimas palabras relacionas que aparece \"Echeverria\" la cual asociamos a la historia del pueblo. Antes de llamarse Ibarlucea se conocia como Cruce de Echeverria. Y otra de las observaciones es \"Iberlucea\" que fue uno de los nombres que tambien tuvo el pueblo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3401f1",
   "metadata": {},
   "source": [
    "## 4\n",
    "\n",
    "Dar 5 ejemplos de analogías. Es necesario reescribir la función analogy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c136025d",
   "metadata": {},
   "source": [
    "No es necesario la reescritura de la funcion, nosotros la volvimos a crear porque partimos de un notebook nuevo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "642e9954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(model, x1, x2, y1):\n",
    "    result = model.most_similar(positive=[y1, x2], negative=[x1])\n",
    "    return result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "688a1cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reina\n",
      "princesa\n"
     ]
    }
   ],
   "source": [
    "print(analogy(model_es, 'actor', 'actriz', 'rey'))\n",
    "print(analogy(model_es, 'niño', 'niña', 'príncipe'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b61d2fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bebió\n",
      "leyó\n"
     ]
    }
   ],
   "source": [
    "print(analogy(model_es, 'comer', 'comió', 'beber'))\n",
    "print(analogy(model_es, 'escribir', 'escribió', 'leer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4bc7896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profesora\n",
      "retrato\n"
     ]
    }
   ],
   "source": [
    "print(analogy(model_es, 'médico', 'enfermera', 'profesor'))\n",
    "print(analogy(model_es, 'autor', 'libro', 'pintor'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae4f450c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frío\n",
      "rotundo\n"
     ]
    }
   ],
   "source": [
    "print(analogy(model_es, 'día', 'noche', 'calor'))\n",
    "print(analogy(model_es, 'verdad', 'mentira', 'éxito')) # no es lo esperado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32cee881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuchillar\n",
      "componer\n"
     ]
    }
   ],
   "source": [
    "print(analogy(model_es, 'llave', 'cerradura', 'cuchillo')) # no es lo esperado\n",
    "print(analogy(model_es, 'lápiz', 'escribir', 'pincel'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9129b42",
   "metadata": {},
   "source": [
    "## 5\n",
    "\n",
    "Dar 1 ejemplo donde el modelo replique sesgos presentes en los datos que considere pernicioso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b65461df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotundo\n"
     ]
    }
   ],
   "source": [
    "print(analogy(model_es, 'verdad', 'mentira', 'éxito')) # no es lo esperado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
